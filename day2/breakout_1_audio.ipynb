{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to PYNQ Audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt install -y sox ffmpeg flac\n",
    "!pip3 install gtts pysndfx speechRecognition pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pysndfx import AudioEffectsChain\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new audio object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BaseOverlay(\"base.bit\")\n",
    "pAudio = base.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bypass audio\n",
    "Users can select either `LINE_IN`, or `HP+MIC` as the input port.\n",
    "**\n",
    "\n",
    "In the following example, we choose `LINE_IN`. To choose `MIC`:\n",
    "```python\n",
    "pAudio.select_microphone()\n",
    "```\n",
    "or choose `LINE_IN`:\n",
    "```python\n",
    "pAudio.select_line_in()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it first with your earbuds out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pAudio.select_microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pAudio.bypass(seconds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record\n",
    "Record a 5-second sample and save it into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pAudio.record(5)\n",
    "pAudio.save(\"data/recording.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and play\n",
    "Load a sample and play the loaded sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pAudio.load(\"data/recording.wav\")\n",
    "pAudio.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding effects\n",
    "Create a new file with effects added. [Information for effects can be found here](https://github.com/carlthome/python-audio-effects/blob/master/pysndfx/dsp.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = AudioEffectsChain().delay().reverb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx(\"data/recording.wav\",\"data/recording.ogg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Play in notebook\n",
    "Since the samples are in 24-bit PCM format, \n",
    "users can play the audio directly in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Audio(\"data/recording.ogg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Text to Speech\n",
    "You can use this wrapper for Google's text-to-speech service to produce natural sounding speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"Hello World\"\n",
    "tts = gTTS(words, \"en\", slow=False)\n",
    "tts.save(\"data/hello.mp3\")\n",
    "mp3 = AudioSegment.from_mp3(\"data/hello.mp3\")\n",
    "mp3.export(\"data/hello.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Audio(\"data/hello.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Speech to Text\n",
    "You can use this wrapper for Google's speech recognition service to extract words from an audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(\"data/hello.wav\") as source:\n",
    "    audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting PCM data\n",
    "\n",
    "Users can display the audio data in notebook:\n",
    "\n",
    "1. Plot the audio signal's amplitude over time.\n",
    "2. Plot the spectrogram of the audio signal.\n",
    "\n",
    "The next cell reads the saved audio file and processes it into a `numpy` array.\n",
    "Note that if the audio sample width is not standard, additional processing\n",
    "is required. In the following example, the `sample_width` is read from the\n",
    "wave file itself (24-bit dual-channel PCM audio, where `sample_width` is 3 bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "wav_path = \"data/hello.wav\"\n",
    "with wave.open(wav_path, 'r') as wav_file:\n",
    "    raw_frames = wav_file.readframes(-1)\n",
    "    num_frames = wav_file.getnframes()\n",
    "    num_channels = wav_file.getnchannels()\n",
    "    sample_rate = wav_file.getframerate()\n",
    "    sample_width = wav_file.getsampwidth()\n",
    "    \n",
    "temp_buffer = np.empty((num_frames, num_channels, 4), dtype=np.uint8)\n",
    "raw_bytes = np.frombuffer(raw_frames, dtype=np.uint8)\n",
    "temp_buffer[:, :, :sample_width] = raw_bytes.reshape(-1, num_channels, \n",
    "                                                    sample_width)\n",
    "temp_buffer[:, :, sample_width:] = \\\n",
    "    (temp_buffer[:, :, sample_width-1:sample_width] >> 7) * 255\n",
    "frames = temp_buffer.view('<i4').reshape(temp_buffer.shape[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Amplitude over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for channel_index in range(num_channels):\n",
    "    plt.figure(num=None, figsize=(15, 3))\n",
    "    plt.title('Audio in Time Domain (Channel {})'.format(channel_index))\n",
    "    plt.xlabel('Time in s')\n",
    "    plt.ylabel('Amplitude')\n",
    "    time_axis = np.arange(0, num_frames/sample_rate, 1/sample_rate)\n",
    "    plt.plot(time_axis, frames[:, channel_index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Frequency spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel_index in range(num_channels):\n",
    "    plt.figure(num=None, figsize=(15, 3))\n",
    "    plt.title('Audio in Frequency Demain (Channel {})'.format(channel_index))\n",
    "    plt.xlabel('Frequency in Hz')\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('Magnitude')\n",
    "    temp = fft(frames[:, channel_index])\n",
    "    yf = temp[1:len(temp)//2]\n",
    "    xf = np.linspace(0.0, sample_rate/2, len(yf))\n",
    "    plt.xlim(20,20000)\n",
    "    plt.plot(xf, abs(yf))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Frequency spectrum over time\n",
    "Use the `classic` plot style for better display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for channel_index in range(num_channels):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    matplotlib.style.use(\"classic\")\n",
    "    plt.figure(num=None, figsize=(15, 3))\n",
    "    plt.title('Signal Spectogram (Channel {})'.format(channel_index))\n",
    "    plt.xlabel('Time in s')\n",
    "    plt.ylim(20,20000)\n",
    "\n",
    "    plt.ylabel('Frequency in Hz')\n",
    "    plt.specgram(frames[:, channel_index], Fs=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
